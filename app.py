import streamlit as st
import pandas as pd
import json
import os
import plotly.express as px
import plotly.graph_objects as go
from collections import defaultdict, Counter
from datetime import datetime, timedelta
from news_collector import NewsCollector

st.set_page_config(
    page_title="ì™¸êµ­ì¸ ì•„ë¥´ë°”ì´íŠ¸ ì±„ìš©ê³µê³  ë‰´ìŠ¤",
    page_icon="ğŸ“°",
    layout="wide"
)

@st.cache_data(ttl=3600)  # 1ì‹œê°„ ìºì‹œ
def load_news_data():
    """ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ"""
    collector = NewsCollector()
    return collector.load_news()

def filter_news_by_date(news_data, days_back):
    """ë‚ ì§œë¡œ ë‰´ìŠ¤ í•„í„°ë§"""
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days_back)
    
    filtered_news = []
    for news in news_data:
        try:
            parsed_date = datetime.fromisoformat(news['parsed_date'].replace('Z', '+00:00'))
            if parsed_date.replace(tzinfo=None) >= start_date:
                filtered_news.append(news)
        except:
            # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ì‹œ í¬í•¨
            filtered_news.append(news)
    
    return filtered_news

def get_daily_stats(news_data):
    """ì¼ë³„ ë‰´ìŠ¤ í†µê³„ ìƒì„±"""
    daily_counts = defaultdict(int)
    daily_news = defaultdict(list)
    
    for news in news_data:
        try:
            parsed_date = datetime.fromisoformat(news['parsed_date'].replace('Z', '+00:00'))
            date_str = parsed_date.strftime('%Y-%m-%d')
            daily_counts[date_str] += 1
            daily_news[date_str].append(news)
        except:
            continue
    
    return daily_counts, daily_news

def estimate_popularity_score(news):
    """ë‰´ìŠ¤ ì¸ê¸°ë„ ì ìˆ˜ ì¶”ì • (ì œëª© ê¸¸ì´, ìš”ì•½ ê¸¸ì´, ì–¸ë¡ ì‚¬ ë“± ê³ ë ¤)"""
    score = 0
    
    # ì œëª©ì— ì¤‘ìš” í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš° ì ìˆ˜ ì¶”ê°€
    important_keywords = ['ì±„ìš©', 'ëª¨ì§‘', 'êµ¬ì¸', 'ê¸‰êµ¬', 'ëŒ€ëŸ‰', 'ìƒì‹œ']
    for keyword in important_keywords:
        if keyword in news['title']:
            score += 10
    
    # ìš”ì•½ì´ ì¶©ì‹¤í•œ ê²½ìš° ì ìˆ˜ ì¶”ê°€
    if news['summary'] and len(news['summary']) > 50:
        score += 5
    
    # ì£¼ìš” ì–¸ë¡ ì‚¬ì¸ ê²½ìš° ì ìˆ˜ ì¶”ê°€
    major_press = ['ì—°í•©ë‰´ìŠ¤', 'KBS', 'MBC', 'SBS', 'ì¡°ì„ ì¼ë³´', 'ì¤‘ì•™ì¼ë³´', 'ë™ì•„ì¼ë³´']
    if any(press in news['press'] for press in major_press):
        score += 15
    
    # ìµœì‹  ë‰´ìŠ¤ì— ê°€ì‚°ì 
    try:
        parsed_date = datetime.fromisoformat(news['parsed_date'].replace('Z', '+00:00'))
        hours_ago = (datetime.now() - parsed_date.replace(tzinfo=None)).total_seconds() / 3600
        if hours_ago < 24:
            score += 10
        elif hours_ago < 48:
            score += 5
    except:
        pass
    
    return score

def get_top_news_by_day(daily_news, top_n=3):
    """ì¼ë³„ ì¸ê¸° ë‰´ìŠ¤ top N ì¶”ì¶œ"""
    top_news_by_day = {}
    
    for date, news_list in daily_news.items():
        # ì¸ê¸°ë„ ì ìˆ˜ë¡œ ì •ë ¬
        scored_news = []
        for news in news_list:
            score = estimate_popularity_score(news)
            scored_news.append((score, news))
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•´ì„œ ìƒìœ„ Nê°œ ì„ íƒ
        scored_news.sort(key=lambda x: x[0], reverse=True)
        top_news_by_day[date] = [news for score, news in scored_news[:top_n]]
    
    return top_news_by_day

def main():
    st.title("ğŸ“° ì™¸êµ­ì¸ ì•„ë¥´ë°”ì´íŠ¸ ì±„ìš©ê³µê³  ë‰´ìŠ¤")
    st.markdown("---")
    
    # íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ“° ì „ì²´ ë‰´ìŠ¤"])
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("í•„í„° ì„¤ì •")
    
    # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
    date_range = st.sidebar.selectbox(
        "ë³´ê¸° ê¸°ê°„",
        ["1ì¼", "3ì¼", "1ì£¼ì¼"],
        index=2
    )
    
    days_map = {"1ì¼": 1, "3ì¼": 3, "1ì£¼ì¼": 7}
    days_back = days_map[date_range]
    
    # ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
    with st.spinner("ë‰´ìŠ¤ ë°ì´í„° ë¡œë”© ì¤‘..."):
        news_data = load_news_data()
    
    if not news_data:
        st.error("ì €ì¥ëœ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € `python news_collector.py`ë¥¼ ì‹¤í–‰í•´ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
        
        # ë°ì´í„° ìˆ˜ì§‘ ë²„íŠ¼
        if st.button("ì§€ê¸ˆ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘í•˜ê¸°", type="primary"):
            with st.spinner("ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... (ì•½ 1-2ë¶„ ì†Œìš”)"):
                collector = NewsCollector()
                fresh_news = collector.collect_all_news(days_back=7)
                collector.save_news(fresh_news)
                st.success("ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
                st.rerun()
        return
    
    # ë‚ ì§œ í•„í„°ë§
    filtered_news = filter_news_by_date(news_data, days_back)
    
    if not filtered_news:
        st.info("ì„ íƒí•œ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í‚¤ì›Œë“œ í•„í„°
    available_keywords = list(set([news['keyword'] for news in filtered_news]))
    selected_keywords = st.sidebar.multiselect(
        "í‚¤ì›Œë“œ í•„í„°",
        available_keywords,
        default=available_keywords
    )
    
    # í‚¤ì›Œë“œë¡œ í•„í„°ë§
    if selected_keywords:
        filtered_news = [news for news in filtered_news if news['keyword'] in selected_keywords]
    
    # ë‚ ì§œìˆœ ì •ë ¬
    filtered_news.sort(key=lambda x: datetime.fromisoformat(x['parsed_date'].replace('Z', '+00:00')), reverse=True)
    
    # ì¼ë³„ í†µê³„ ë° ì¸ê¸° ë‰´ìŠ¤ ìƒì„±
    daily_counts, daily_news = get_daily_stats(filtered_news)
    top_news_by_day = get_top_news_by_day(daily_news)
    
    # ëŒ€ì‹œë³´ë“œ íƒ­
    with tab1:
        st.header("ğŸ“Š ë‰´ìŠ¤ í†µê³„ ëŒ€ì‹œë³´ë“œ")
        
        # ê¸°ë³¸ í†µê³„
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ ë‰´ìŠ¤ ìˆ˜", len(filtered_news))
        with col2:
            if filtered_news:
                latest_date = max([datetime.fromisoformat(news['parsed_date'].replace('Z', '+00:00')) for news in filtered_news])
                st.metric("ìµœì‹  ë‰´ìŠ¤", latest_date.strftime('%Y-%m-%d'))
        with col3:
            unique_press = len(set([news['press'] for news in filtered_news if news['press']]))
            st.metric("ì–¸ë¡ ì‚¬ ìˆ˜", unique_press)
        
        st.markdown("---")
        
        # ì¼ë³„ ë‰´ìŠ¤ ìˆ˜ ì°¨íŠ¸
        if daily_counts:
            st.subheader("ğŸ“ˆ ì¼ë³„ ë‰´ìŠ¤ ìˆ˜")
            
            # ë°ì´í„° ì¤€ë¹„
            dates = sorted(daily_counts.keys())
            counts = [daily_counts[date] for date in dates]
            
            # ì°¨íŠ¸ ìƒì„±
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=dates,
                y=counts,
                text=counts,
                textposition='auto',
                marker_color='lightblue'
            ))
            fig.update_layout(
                title=f"ìµœê·¼ {date_range} ì¼ë³„ ë‰´ìŠ¤ ìˆ˜",
                xaxis_title="ë‚ ì§œ",
                yaxis_title="ë‰´ìŠ¤ ìˆ˜",
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # í‚¤ì›Œë“œë³„ ì°¨íŠ¸
            keyword_counts = Counter([news['keyword'] for news in filtered_news])
            if len(keyword_counts) > 1:
                st.subheader("ğŸ·ï¸ í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ë¶„í¬")
                
                fig2 = px.pie(
                    values=list(keyword_counts.values()),
                    names=list(keyword_counts.keys()),
                    title="í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ë¹„ìœ¨"
                )
                st.plotly_chart(fig2, use_container_width=True)
        
        st.markdown("---")
        
        # ì¼ë³„ ì¸ê¸° ë‰´ìŠ¤ TOP 3
        if top_news_by_day:
            st.subheader("ğŸ”¥ ì¼ë³„ ì¸ê¸° ë‰´ìŠ¤ TOP 3")
            
            for date in sorted(top_news_by_day.keys(), reverse=True):
                with st.expander(f"ğŸ“… {date} ({len(daily_news[date])}ê°œ ë‰´ìŠ¤)"):
                    top_news = top_news_by_day[date]
                    
                    for i, news in enumerate(top_news, 1):
                        st.markdown(f"**{i}. [{news['title']}]({news['link']})**")
                        st.write(f"ğŸ“° {news['press']} | ğŸ·ï¸ {news['keyword']}")
                        if news['summary']:
                            st.write(f"ğŸ’¬ {news['summary'][:100]}...")
                        st.markdown("---")
    
    # ì „ì²´ ë‰´ìŠ¤ íƒ­
    with tab2:
        st.header("ğŸ“° ì „ì²´ ë‰´ìŠ¤ ëª©ë¡")
        
        # ë‰´ìŠ¤ í‘œì‹œ
        for i, news in enumerate(filtered_news):
            with st.container():
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.markdown(f"### [{news['title']}]({news['link']})")
                    if news['summary']:
                        st.write(news['summary'])
                    st.caption(f"í‚¤ì›Œë“œ: {news['keyword']}")
                
                with col2:
                    st.write(f"**ì–¸ë¡ ì‚¬:** {news['press']}")
                    st.write(f"**ë‚ ì§œ:** {news['date']}")
                
                st.markdown("---")
        
        # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        if filtered_news:
            df = pd.DataFrame(filtered_news)
            csv = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"ì™¸êµ­ì¸_ì•„ë¥´ë°”ì´íŠ¸_ë‰´ìŠ¤_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
    
    # ë°ì´í„° ê°±ì‹  ë²„íŠ¼
    st.sidebar.markdown("---")
    if st.sidebar.button("ğŸ”„ ë‰´ìŠ¤ ë°ì´í„° ê°±ì‹ ", type="secondary"):
        with st.spinner("ìƒˆë¡œìš´ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... (ì•½ 1-2ë¶„ ì†Œìš”)"):
            collector = NewsCollector()
            fresh_news = collector.collect_all_news(days_back=7)
            collector.save_news(fresh_news)
            st.sidebar.success("ë°ì´í„° ê°±ì‹  ì™„ë£Œ!")
            st.rerun()
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    with st.expander("ğŸ’¡ ì‚¬ìš©ë²• ì•ˆë‚´"):
        st.markdown("""
        ### ì´ ì•±ì˜ ê¸°ëŠ¥
        - **ë¯¸ë¦¬ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ í‘œì‹œ**: ì™¸êµ­ì¸ ì•„ë¥´ë°”ì´íŠ¸ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë¯¸ë¦¬ ìˆ˜ì§‘í•´ì„œ ë¹ ë¥´ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤
        - **ë‚ ì§œ í•„í„°ë§**: 1ì¼, 3ì¼, 1ì£¼ì¼ ë‹¨ìœ„ë¡œ ë‰´ìŠ¤ë¥¼ í•„í„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        - **í‚¤ì›Œë“œ í•„í„°ë§**: íŠ¹ì • í‚¤ì›Œë“œë§Œ ê³¨ë¼ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        - **ì‹¤ì‹œê°„ ê°±ì‹ **: ë‰´ìŠ¤ ë°ì´í„° ê°±ì‹  ë²„íŠ¼ìœ¼ë¡œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        
        ### ë°ì´í„° ìˆ˜ì§‘ í‚¤ì›Œë“œ
        - ì™¸êµ­ì¸ ì•„ë¥´ë°”ì´íŠ¸
        - ì™¸êµ­ì¸ ì•Œë°”
        - ì™¸êµ­ì¸ ì±„ìš©
        - ì™¸êµ­ì¸ êµ¬ì¸
        - ì™¸êµ­ì¸ ê·¼ë¡œì ì±„ìš©
        - ì™¸êµ­ì¸ ì§ì› ëª¨ì§‘
        
        ### ìˆ˜ë™ ë°ì´í„° ìˆ˜ì§‘
        í„°ë¯¸ë„ì—ì„œ `python news_collector.py`ë¥¼ ì‹¤í–‰í•˜ë©´ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """)

if __name__ == "__main__":
    main()